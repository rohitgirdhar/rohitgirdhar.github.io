<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: May 7, 2025 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.6" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="./css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
      
        
      
        
      
        
      
        
      
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="./css/wowchemy.50b7bdfac32c4ce0cd2b02456081e75d.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="./css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="./css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Rohit Girdhar" />





  

<meta name="description" content="A highly-customizable Hugo academic resume theme powered by Hugo Blox Builder." />



<link rel="alternate" hreflang="en-us" href="https://rohitgirdhar.github.io/" />
<link rel="canonical" href="https://rohitgirdhar.github.io/" />



  <link rel="manifest" href="./manifest.webmanifest" />



<link rel="icon" type="image/png" href="./media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="./media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@GetResearchDev" />
  <meta property="twitter:creator" content="@GetResearchDev" />
<meta property="twitter:image" content="https://rohitgirdhar.github.io/media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_512x512_fill_lanczos_center_3.png" />



  
    
    <meta property="profile:first_name" content="Rohit">
    <meta property="profile:last_name" content="Girdhar">
  

<meta property="og:type" content="profile" />
<meta property="og:site_name" content="Rohit Girdhar" />
<meta property="og:url" content="https://rohitgirdhar.github.io/" />
<meta property="og:title" content="Rohit Girdhar" />
<meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Hugo Blox Builder." /><meta property="og:image" content="https://rohitgirdhar.github.io/media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2024-01-01T00:00:00&#43;00:00" />
  





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://rohitgirdhar.github.io?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "https://rohitgirdhar.github.io"
}
</script>


  




  
  
  

  
  
    <link rel="alternate" href="./index.xml" type="application/rss+xml" title="Rohit Girdhar" />
  

  


  
  <title>Rohit Girdhar</title>

  
  
  
     
<script async defer src="https://buttons.github.io/buttons.js"></script>

  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" class="page-wrapper   " data-wc-page-id="3976528693a0108357f4928017600865" >

  
  
  
  
  
  
  
  
  
  <script src="./js/wowchemy-init.min.3a6bdbdff5d8a89d6e651adb3deec035.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="./">Rohit Girdhar</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="./">Rohit Girdhar</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="./#about" data-target="#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="./#projects" data-target="#projects"><span>Projects</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://twitter.com/_rohitgirdhar_" data-toggle="tooltip" data-placement="bottom" title="Follow me on Twitter" target="_blank" rel="noopener" aria-label="Follow me on Twitter">
                <i class="fab fa-twitter" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    


  









  

<span class="js-widget-page d-none"></span>



  
  

  
  
    





























































<section id="about" class="home-section wg-about-biography  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  

    









  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle"
           width="270" height="270"
           src="./authors/admin/avatar_hu1d08cb65f394ab7b2a5007b0ec61acd0_44298_270x270_fill_q75_lanczos_center.jpg" alt="Rohit Girdhar">
      

      <div class="portrait-title">

        <h2>Rohit Girdhar</h2>

        <h3>Research Scientist</h3>

        
        <h3>
          <a href="https://www.meta.com/" target="_blank" rel="noopener">
          <span>GenAI Research, Meta</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
        <li>
          <a href="mailto:rgirdhar@alumni.cmu.edu"  aria-label="envelope">
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://twitter.com/_rohitgirdhar_" target="_blank" rel="noopener" aria-label="twitter">
            <i class="fab fa-twitter big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.co.in/citations?user=7cuwdr8AAAAJ&amp;hl=en" target="_blank" rel="noopener" aria-label="graduation-cap">
            <i class="fas fa-graduation-cap big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/rohitgirdhar" target="_blank" rel="noopener" aria-label="github">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://www.linkedin.com/in/rohit-girdhar-53382881/" target="_blank" rel="noopener" aria-label="linkedin">
            <i class="fab fa-linkedin big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    

    
    <div class="article-style">
      <!-- I am a research scientist at GenAI at Meta, working on computer vision and machine learning. My current research focuses on understanding and generating multimodal data, using minimal human supervision. I obtained a PhD from Carnegie Mellon University (CMU) where I worked with <a href="http://cs.cmu.edu/~deva">Deva Ramanan</a> (here's a link to my <a href="https://drive.google.com/file/d/1AlH0aRYJ9W22GONsIhIT6t7CDSIDBBHV/view?usp=sharing">dissertation</a>).  -->
  <!-- <a href="https://doi.org/10.1184/R1/9816491.v1">dissertation</a>). -->
  <!-- Earlier I graduated with a masters from CMU as well, working with
	<a href="http://cs.cmu.edu/~hebert">Martial Hebert</a>,
	<a href="http://cs.cmu.edu/~abhinavg">Abhinav Gupta</a>,
	<a href="http://cs.cmu.edu/~kkitani">Kris Kitani</a> and
	<a href="https://people.eecs.berkeley.edu/~dfouhey/">David Fouhey</a> as a
  <a href="https://en.wikipedia.org/wiki/Siebel_Scholars">Siebel Scholar</a>. Even before
  I was a CS undergrad at IIIT, Hyderabad, working with
  <a href="https://www.iiit.ac.in/~jawahar/">C. V. Jawahar</a>.
  I have also been fortunate to work with some amazing people through internships, at DeepMind (with
      <a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>,
      <a href="https://scholar.google.com/citations?user=IUZ-7_cAAAAJ&hl=en">João Carreira</a> and
      <a href="http://www.carldoersch.com">Carl Doersch</a>), Adobe Research (with
	<a href="http://www.di.ens.fr/~josef/">Josef Sivic</a> and
  <a href="http://bryanrussell.org/">Bryan Russell</a>)
  and Facebook AI (with <a href="http://www.cs.dartmouth.edu/~lorenzo/home.html">Lorenzo Torresani</a>,
	<a href="https://gkioxari.github.io/">Georgia Gkioxari</a> and <a href="https://dutran.github.io/">Du Tran</a>). -->
<!-- # Formal bio -->
<p style="text-align: justify;">I am a Research Scientist in the GenAI Research group at Meta. My current research focuses on understanding and generating multimodal data, using minimal human supervision. I obtained a MS and PhD in Robotics from Carnegie Mellon University (here&rsquo;s a link to my <a href="https://drive.google.com/file/d/1AlH0aRYJ9W22GONsIhIT6t7CDSIDBBHV/view?usp=sharing">dissertation</a>), where I worked on learning from and understanding videos. I was previously part of the Facebook AI Research (FAIR) group at Meta, and have spent time at DeepMind, Adobe and Facebook as an intern.
See <a href="assets/bio.txt" target="_blank">here</a> for a formal bio.</p>
<h3>News</h3>
<ul>
  <li>[October'2024] Mark Zuckerberg <a href="https://www.instagram.com/reel/DAs_J17Pw0G/" target="_blank">announced</a> our work on MovieGen, the new state-of-the-art media generation and editing system, outperforming SORA, Emu Video and more! Covered in
  <a href="https://www.nytimes.com/2024/10/04/technology/meta-instant-ai-video-generator-adds-sounds.html", target="_blank">NY Times</a>,
  <a href="https://www.ft.com/content/00c9ce12-68f7-4fdd-a35f-8a66cc63420d", target="_blank">FT</a>,
  <a href="https://www.forbes.com/sites/johnwerner/2024/10/20/movies-of-the-future-are-here-now-with-meta-movie-gen/", target="_blank">Forbes</a>,
  <a href="https://www.wired.com/story/meta-movie-gen-ai-model/", target="_blank">WIRED</a>,
  <a href="https://www.bloomberg.com/news/articles/2024-10-04/meta-unveils-ai-video-generator-taking-on-openai-and-google", target="_blank">Bloomberg</a>,
  <a href="https://techcrunch.com/2024/10/04/metas-movie-gen-model-puts-out-realistic-video-with-sound-so-we-can-finally-have-infinite-moo-deng/", target="_blank">TechCrunch</a>, etc.
  <li>[July'2024] Mark Zuckerberg <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank">announced</a> Llama 3.1, along with our state-of-the-art video recognition capabilities!
  <li>[June'2024] Invited panelist for the AI for <a href="https://ai4cc.net/" target="_blank">Content Creation (AI4CC)</a> workshop at CVPR 2024 (along with <a href="https://www.linkedin.com/in/jingwanlu" target="_blank">Cynthia Lu</a> and <a href="https://scholar.google.com/citations?user=ygdQhrIAAAAJ" target="_blank">Robin Rombach</a>).
  <li>[June'2024] <a href="https://facebookresearch.github.io/LaViLa/" target="_blank">LaViLa</a> and <a href="https://ego4d-data.org/" target="_blank">Ego4D</a> among the winners of the <a href="https://egovis.github.io/awards/2022_2023/" target="_blank">EgoVis 2022-23 Distinguished Paper Awards</a>!
  <li>[April'2024] Presented Emu Video at RunwayML's inaugural <a href="https://runwayml.com/research/rna-sessions" target="_blank">Research and Art (RNA)</a> <a href="https://www.linkedin.com/posts/runwayml_last-night-we-hosted-our-inaugural-research-activity-7189310098761035778-PilQ/" target="_blank">event</a>.
  <li>[Feb'2024] Invited judge for the <a href="https://engage.mit.edu/fma/invited-speakers" target="_blank">MIT Filmmaking Hackathhon 2024</a>.
  <li>[April'2024] <tt>/animate</tt> functionality based on <a href="https://emu-video.metademolab.com/" target="_blank">Emu Video</a> is publicly released! Try it out to animate images generated using <tt>/imagine</tt> on <a href="https://www.meta.ai/" target="_blank">meta.ai</a>!
  <li>[Nov'2023] Mark Zuckerberg <a href="https://www.facebook.com/reel/1330584860932048" target="_blank">announced</a> our state-of-the-art video generation work, <a href="https://emu-video.metademolab.com/" target="_blank">Emu Video</a>! Also see coverage by <a href="https://techcrunch.com/2023/11/16/meta-brings-us-a-step-closer-to-ai-generated-movies/" target="_blank">TechCrunch</a>, <a href="https://www.theverge.com/2023/11/16/23963999/meta-facebook-instagram-ai-image-video-editing-emu-announcement" target="_blank">TheVerge</a>,  <a href="https://venturebeat.com/ai/metas-new-ai-milestone-emu-video-and-emu-edit-set-to-revolutionize-text-to-video-generation-and-image-editing/" target="_blank">VentureBeat</a>, <a href="https://www.reuters.com/technology/meta-launches-ai-based-video-editing-tools-2023-11-16/" target="_blank">Reuters</a>, and <a href="https://www.google.com/search?q=EmuVideo&tbm=nws" target="_blank">others</a>!</li>
  <li> [Oct'2023] Giving talks at the <a href="https://dimadamen.github.io/VideoAI2023/" target="_blank">DeepMind AI Video symposium</a>, and <a href="https://ptchallenge-workshop.github.io/" target="_blank">Perception Test workshop</a> at ICCV 2023 (<a href="https://www.youtube.com/watch?v=BJavPGmEW7M&t=10206s" target="_blank">video</a>).
  <li>[June'2023] Giving a talk at <a href="https://holistic-video-understanding.github.io/workshops/cvpr2023.html" target="_blank">HVU Workshop</a> and presenting 5 papers at CVPR 2023!</li>
  <li>[May'2023] Mark Zuckerberg <a href="https://www.facebook.com/4/videos/957710632033177/" target="_blank">announced</a> our multimodal embedding work, <a href="https://imagebind.metademolab.com/" target="_blank">ImageBind</a>! Also see coverage by <a href="https://www.theverge.com/2023/5/9/23716558/meta-imagebind-open-source-multisensory-modal-ai-model-research" target="_blank">TheVerge</a>,  <a href="https://www.engadget.com/metas-open-source-imagebind-ai-aims-to-mimic-human-perception-181500560.html" target="_blank">Engadget</a>, <a href="https://siliconangle.com/2023/05/09/meta-open-sources-multimodal-imagebind-model-advance-ai-research/" target="_blank">SiliconANGLE</a>, <a href="https://www.maginative.com/article/meta-introduces-imagebind-an-ai-model-that-learns-across-six-modalities/" target="_blank">maginative</a> and <a href="https://www.google.com/search?q=ImageBind&tbm=nws">others</a>!</li>
  <li>[June'2022] Presenting 3 papers at CVPR 2022, including <a href="https://facebookresearch.github.io/omnivore/" target="_blank">Omivore</a>, a single model that obtains state-of-the-art results across 3 different modalities: images, videos and single-view 3D!
  <li>[Oct'2021] We announced <a href="https://ego4d-data.org/", target="_blank">Ego4D</a>, the largest egocentric video dataset to date! See <a href="https://www.youtube.com/watch?v=taC2ZKl9IsE", target="_blank">this video</a> for a quick intro, and see coverage from <a href="https://techcrunch.com/2021/10/14/facebook-researchers-collect-thousands-of-hours-of-first-person-video-to-train-ai/" target="_blank">TechCrunch</a>, <a href="https://www.theverge.com/2021/10/14/22725894/facebook-augmented-reality-ar-glasses-ai-systems-ego4d-research" target="_blank">TheVerge</a>, <a href="https://www.axios.com/2021/10/14/facebook-first-person-ai-data" target="_blank">Axios</a>, <a href="https://www.fastcompany.com/90686015/facebook-ar-glasses-video-research" target="_blank">Fast Company</a>, and <a href="https://www.google.com/search?q=Ego4D&tbm=nws">others</a>!
</ul>

    </div>
    

    <div class="row">

      

      
      <div class="col-md-6">
        <div class="section-subheading">Education</div>
        <ul class="ul-edu fa-ul mb-0">
          
          <li>
            <i class="fa-li fa-solid fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Robotics, 2019</p>
              <p class="institution">Carnegie Mellon University, Pittsburgh PA</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MS in Robotics, 2016</p>
              <p class="institution">Carnegie Mellon University, Pittsburgh PA</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-graduation-cap"></i>
            <div class="description">
              <p class="course">B. Tech. in Computer Science, 2014</p>
              <p class="institution">IIIT Hyderabad, India</p>
            </div>
          </li>
          
        </ul>
      </div>
      

      
      <div class="col-md-6">
        <div class="section-subheading">Experience</div>
        
        <ul class="ul-edu fa-ul mb-0">
          
          <li>
            <i class="fa-li fa-solid fa-briefcase"></i>
            <div class="description">
              <p class="course"><b>Meta</b> &middot; Research Scientist</p>
              <p class="institution"><b>New York</b> &middot; 2019 -- Present</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-briefcase"></i>
            <div class="description">
              <p class="course"><b>DeepMind</b> &middot; Research Scientist Intern</p>
              <p class="institution"><b>London</b> &middot; Summer 2018</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-briefcase"></i>
            <div class="description">
              <p class="course"><b>Facebook</b> &middot; Research Scientist Intern</p>
              <p class="institution"><b>Menlo Park</b> &middot; Summer 2017</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-briefcase"></i>
            <div class="description">
              <p class="course"><b>Adobe</b> &middot; Research Scientist Intern</p>
              <p class="institution"><b>San Francisco</b> &middot; Summer 2016</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa-solid fa-briefcase"></i>
            <div class="description">
              <p class="course"><b>Facebook</b> &middot; Software Engineering Intern</p>
              <p class="institution"><b>Menlo Park</b> &middot; Summer 2013</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>


  

  </div>
</section>

  

  
  
    





























































<section id="section-markdown" class="home-section wg-markdown  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Highlights</h1>
          <p class="mt-1">Videos powered by MovieGen and Emu Video!</p>
        </div>
      
    
  

    










  <div class="col-12 col-lg-8">
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/FHSSx4dUs7E" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
<br>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/QODf8MW_UtA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
  </div>



  
    </div>
  

  </div>
</section>

  

  
  
    





























































<section id="projects" class="home-section wg-portfolio  "  >
 <div class="home-section-bg " >
   
 </div>
  <div class="container">

  
    <div class="row  ">
    
      
        <div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
          <h1 class="mb-0">Projects and Publications</h1>
          
        </div>
      
    
  

    












<div class="col-12 col-lg-8">

  

  

    

    
    
    
    
      
      
        
      
    

    <span class="d-none default-project-filter">.js-id-selected</span>

    
    
    <div class="project-toolbar">
      <div class="project-filters">
        <div class="btn-toolbar ">
          <div class="btn-group flex-wrap">
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-selected" class="btn btn-primary btn-lg active">Selected</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-generative" class="btn btn-primary btn-lg">Generative</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-multimodal" class="btn btn-primary btn-lg">Multimodal</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-video" class="btn btn-primary btn-lg">Video</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-threed" class="btn btn-primary btn-lg">3D</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-representation" class="btn btn-primary btn-lg">Representation</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter=".js-id-spatial" class="btn btn-primary btn-lg">Detection</a>
            
              
              
              
                
                  
                
              
              <a href="#" data-filter="*" class="btn btn-primary btn-lg">All</a>
            
          </div>
        </div>
      </div>
    </div>
    
  

  <div class="isotope projects-container row js-layout-row ">

    
    

    
    
    
      
    
    
    
    
      
    

    
    
    
    
    
    

    
      
        
          <div class="col-12 isotope-item js-id-generative">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Yinbo Chen</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Xiaolong Wang</span>, <span >
      Sai Saketh Rambhatla</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2025
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2025
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2025_dito/featured_hucfdf306d236370f532f0af487a4c8716_124229_70c93378d8408c6be0793ac1166ae6a0.webp" height="455" width="527"
            class="article-banner" alt="Diffusion Autoencoders are Scalable Image Tokenizers" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener">Diffusion Autoencoders are Scalable Image Tokenizers</a>
  </div>

  
  <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Simplified image tokenization using diffusion</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2501.18593" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2025_dito/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/yinboc/dito"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-generative">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Kumar Ashutosh</span>, <span >
      Yossi Gandelsman</span>, <span >
      Xinlei Chen</span>, <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2025
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICML</em>, 2025
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2025_mils/featured_hu91feacf1bbb98f48740cb256b1527f7a_164182_3798525b5b5307f19dbfe84a760f21cb.webp" height="455" width="780"
            class="article-banner" alt="LLMs can see and hear without any training" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener">LLMs can see and hear without any training</a>
  </div>

  
  <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Pure text-only LLMs can use off-the-shelf multimodal embedding models to do various multimodal tasks!</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2501.18096" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2025_mils/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/MILS"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-generative js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Shijie Wang</span>, <span >
      Samaneh Azadi</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Saketh Rambhatla</span>, <span >
      Chen Sun</span>, <span >
      Xi Yin</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2025
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2024_motif/featured_hub25141231e5184dde9bd7ca203a40cc3_3677564_808x455_fit_lanczos_1.gif" height="455" width="455"
            class="article-banner" alt="MotiF: Making Text Count in Image Animation with Motion Focal Loss" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener">MotiF: Making Text Count in Image Animation with Motion Focal Loss</a>
  </div>

  
  <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Using flow to improve motion in video generation</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2412.16153" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_motif/cite.bib">
  Cite
</a>
















  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-generative js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      MovieGen team (core-contributor)</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2024_moviegen/featured_huf61b023c4e2bacd75707a055675aec31_18135496_808x455_fit_lanczos_1.gif" height="363" width="640"
            class="article-banner" alt="Movie Gen: A Cast of Media Foundation Models" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener">Movie Gen: A Cast of Media Foundation Models</a>
  </div>

  
  <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>State-of-the-Art Video (+Audio) Generation Model</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2410.13720" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_moviegen/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/playlist?list=PL86eLlsPNfyi27GSizYjinpYxp7gEl5K8" target="_blank" rel="noopener">
  Video
</a>







  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Llama3 team (co-lead the video recognition efforts)</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2024_llama3/featured_hufc261de3a2ba4597fdb3fa01ac601ce8_5670404_808x455_fit_lanczos_1.gif" height="360" width="640"
            class="article-banner" alt="The Llama 3 Herd of Models" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener">The Llama 3 Herd of Models</a>
  </div>

  
  <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>State-of-the-Art open-source LLM with multimodal capabilities</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2407.21783" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_llama3/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/meta-llama/llama3"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-multimodal js-id-video js-id-representation">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Changan Chen</span>, <span >
      Ashutosh Kumar</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      David Harwath</span>, <span >
      Kristen Grauman</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2024_soundingactions/featured_hu5df24b2c8c9426da5f6e4473bf397161_383944_1e10463eb7cd0c8d6ea4c4e7c198b92a.webp" height="135" width="808"
            class="article-banner" alt="SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener">SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos</a>
  </div>

  
  <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Self-supervised embedding to learn how actions sound from narrated in-the-wild egocentric videos.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2404.05206" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_soundingactions/cite.bib">
  Cite
</a>
















  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-spatial js-id-generative">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Xudong Wang</span>, <span >
      Trevor Darrell</span>, <span >
      Sai Saketh Rambhatla</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February, 2024
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2024_instancediffusion/featured_hud09c74df147add9c2899425b89b23763_1717176_e5051e04f007628d9d7a148386622998.webp" height="455" width="806"
            class="article-banner" alt="InstanceDiffusion: Instance-level Control for Image Generation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener">InstanceDiffusion: Instance-level Control for Image Generation</a>
  </div>

  
  <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>SOTA instance-conditioned diffusion model for image generation.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2402.03290" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_instancediffusion/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/frank-xwang/InstanceDiffusion"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-generative js-id-multimodal">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Sachit Menon</span>, <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_illustratedinstructions/featured_huec897810e004554b234f684b1bd78268_967715_808x455_fit_lanczos_1.gif" height="285" width="256"
            class="article-banner" alt="Generating Illustrated Instructions" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener">Generating Illustrated Instructions</a>
  </div>

  
  <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Introducing a new task of generating instructions for the task you want to solve with illustrations, and a LLM + Diffusion model based solution.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2312.04552" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_illustratedinstructions/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/sachit-menon/generating-illustrated-instructions-reproduction"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-generative js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Wilson Yan</span>, <span >
      Andrew Brown</span>, <span >
      Pieter Abbeel</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Samaneh Azadi</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_moca/featured_hu76aa32fa7e20fb2e5469631e3ce3167c_1637060_808x455_fit_lanczos_1.gif" height="256" width="512"
            class="article-banner" alt="Motion-Conditioned Image Animation for Video Editing" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener">Motion-Conditioned Image Animation for Video Editing</a>
  </div>

  
  <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Image animation FTW again! SOTA video editing results by animating the first frame with motion conditioning.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2311.18827" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_moca/cite.bib">
  Cite
</a>
















  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-spatial js-id-representation js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Xudong Wang</span>, <span >
      Ishan Misra</span>, <span >
      Ziyun Zeng</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Trevor Darrell</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2024
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_videocutler/featured_hu62e25aa308c4350caede4d3036165c7a_1324831_808x455_fit_lanczos_1.gif" height="99" width="512"
            class="article-banner" alt="VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener">VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation</a>
  </div>

  
  <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>SOTA unsupervised video segmentation using CutLER.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2308.14710" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_videocutler/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/CutLER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-generative js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution, Equal First Author"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution, Equal First Author"></i>, <span >
      Andrew Brown</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Quentin Duval</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Samaneh Azadi</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Sai Saketh Rambhatla</span>, <span >
      Akbar Shah</span>, <span >
      Xi Yin</span>, <span >
      Devi Parikh</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_emuvideo/featured_hu8a73aaf727f04e5575bcfb73288cf035_5778464_808x455_fit_lanczos_1.gif" height="455" width="455"
            class="article-banner" alt="Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener">Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning</a>
  </div>

  
  <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>A simple and effective approach to high-quality video generation by learning to animate high quality images.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2311.10709" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_emuvideo/cite.bib">
  Cite
</a>
















  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.meta.ai/" target="_blank" rel="noopener">
  Demo
</a>

  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alaaeldin El-Nouby</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Zhuang Liu</span>, <span >
      Mannat Singh</span>, <span >
      Kalyan Vasudev Alwala</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2023 <strong>(Highlighted Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_imagebind/featured_huf79a6f7bcfb9d796f8906556960fe5f8_1189239_808x455_fit_lanczos_1.gif" height="455" width="556"
            class="article-banner" alt="ImageBind: One Embedding Space To Bind Them All" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener">ImageBind: One Embedding Space To Bind Them All</a>
  </div>

  
  <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>One embedding space for 6 different modalities, enables zero-shot recognition on all modalities!</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2305.05665" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_imagebind/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/W_zw4Lrdt1s" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/ImageBind"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-representation js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Quentin Duval</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Kalyan Vasudev Alwala</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Haoqi Fan</span>, <span >
      Vaibhav Aggarwal</span>, <span >
      Aaron Adcock</span>, <span >
      Armand Joulin</span>, <span >
      Piotr Dollár</span>, <span >
      Christoph Feichtenhofer</span>, <span >
      Ross Girshick</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICCV</em>, 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_maws/featured_hu9284505d0476bd57b25a1d4ef0ac7f95_215781_1e4d45b8b7eca11bbb4a62feead9c15c.webp" height="455" width="550"
            class="article-banner" alt="The effectiveness of MAE pre-pretraining for billion-scale pretraining" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener">The effectiveness of MAE pre-pretraining for billion-scale pretraining</a>
  </div>

  
  <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Scaling up MAE pre-pretraining, followed by weakly supervised pretraining, leads to strong representations.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2303.13496" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_maws/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/maws"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-spatial js-id-representation">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Xudong Wang</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Stella X. Yu</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_cutler/featured_hu71b3a50d5002fb490e347fa62c3e542a_1146224_312b4dcb316346bbe366f6f38e24eed7.webp" height="226" width="808"
            class="article-banner" alt="CutLER: Cut and Learn for Unsupervised Object Detection and Instance Segmentation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener">CutLER: Cut and Learn for Unsupervised Object Detection and Instance Segmentation</a>
  </div>

  
  <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Discovering objects using DINO features, and learning an unsupervised detection + segmentation model</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2301.11320" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_cutler/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/CutLER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Kumar Ashutosh</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Lorenzo Torresani</span>, <span >
      Kristen Grauman</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2023 <strong>(Highlighted Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2023_hiervl/featured_hu313c0cd81089a238e84337ce628a6b31_182541_31c53492815e1b59ad40b87f878517b4.webp" height="455" width="558"
            class="article-banner" alt="HierVL: Learning Hierarchical Video-Language Embeddings" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener">HierVL: Learning Hierarchical Video-Language Embeddings</a>
  </div>

  
  <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Video-language embeddings are a promising avenue for injecting semantics into visual representations, but existing methods capture only short-term associations between seconds-long video clips and their accompanying text. We propose HierVL, a novel hierarchical video-language embedding that simultaneously accounts for both long-term and short-term associations.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2301.02311" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_hiervl/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=I5FIGHc_H5I" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/HierVL"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Yue Zhao</span>, <span >
      Ishan Misra</span>, <span >
      Philipp Krähenbühl</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2023 <strong>(Highlighted Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2022_lavila/featured_hub4c92471f059118ff9c3704afc0435e3_3559165_808x455_fit_lanczos_1.gif" height="385" width="512"
            class="article-banner" alt="Learning Video Representations from Large Language Models" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener">Learning Video Representations from Large Language Models</a>
  </div>

  
  <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Leveraging LLMs to auto-annotate videos for representation learning.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2212.04501" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_lavila/cite.bib">
  Cite
</a>














  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://colab.research.google.com/drive/1gHWiEWywIotRivYQTR-8NQ6GJC7sJUe4" target="_blank" rel="noopener">
    Colab
</a>


  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/LaViLa"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-representation js-id-multimodal js-id-video">
        
        











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alaaeldin El-Nouby</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Kalyan Vasudev Alwala</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2023
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="./publication/2022_omnimae/" >
      <div class="img-hover-zoom">
        <img src="./publication/2022_omnimae/featured_hu1a7555a1b49baa03e14d96a4ba36e4c9_231964_0b896000ba65e1bf2820beb3eab4e26a.webp" height="250" width="808"
            class="article-banner" alt="OmniMAE: Single Model Masked Pretraining on Images and Videos" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="./publication/2022_omnimae/" >OmniMAE: Single Model Masked Pretraining on Images and Videos</a>
  </div>

  
  <a href="./publication/2022_omnimae/"  class="summary-link">
    <div class="article-style">
      <p>Single self-supervised representation for images and videos.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2206.08356" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_omnimae/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/qef4wWCytc4" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/omnivore"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-representation js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Nikhila Ravi</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Laurens van der Maaten</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2022 <strong>(Oral Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2022_omnivore/featured_hu9cf3a85deea45bc635e5e78593f4f7a4_3052575_ab0674297e9711886712d634b30f94a9.webp" height="300" width="808"
            class="article-banner" alt="Omnivore: A Single Model for Many Visual Modalities" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener">Omnivore: A Single Model for Many Visual Modalities</a>
  </div>

  
  <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>A single model for images, video and single-view 3D.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2201.08377" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_omnivore/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/omnivore"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-multimodal js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Kristen Grauman</span>, <span >
      Andrew Westbury</span>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      et al</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2022 <strong><a href="https://twitter.com/CVPR/status/1539258447752994816" target="_blank" rel="noopener">(Best paper finalist)</a></strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://ego4d-data.org/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2022_ego4d/featured_hufaa5e2cae9d4f5980a8400d6f4dcc2af_4298806_808x455_fit_lanczos_1.gif" height="225" width="400"
            class="article-banner" alt="Ego4D: Around the World in 3,000 Hours of Egocentric Video" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://ego4d-data.org/" target="_blank" rel="noopener">Ego4D: Around the World in 3,000 Hours of Egocentric Video</a>
  </div>

  
  <a href="https://ego4d-data.org/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>The largest egocentric video dataset.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2110.07058" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_ego4d/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=taC2ZKl9IsE" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Ego4D"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-spatial js-id-representation">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Xingyi Zhou</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>, <span >
      Philipp Krähenbühl</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ECCV</em>, 2022
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2022_detic/featured_hube32d62ba727a7e82c20c4a95ae4062f_140416_14df91da150cedfcac3743956ec33c5b.webp" height="455" width="607"
            class="article-banner" alt="Detecting Twenty-thousand Classes using Image-level Supervision" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener">Detecting Twenty-thousand Classes using Image-level Supervision</a>
  </div>

  
  <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Leverages image classification data to build an object detector</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2201.02605" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_detic/cite.bib">
  Cite
</a>














  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://colab.research.google.com/drive/1QtTW9-ukX2HKZGvt0QvVGqjuqEykoZKI" target="_blank" rel="noopener">
    Colab
</a>


  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Detic"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-video js-id-spatial">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Bowen Cheng</span>, <span >
      Anwesa Choudhuri</span>, <span >
      Ishan Misra</span>, <span >
      Alexander Kirillov</span>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alexander G. Schwing</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>arXiv</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_videomask2former/featured_hu122a5880287eedad687316b306034f46_636930_017be73c8989c62f2324ab82603dca3c.webp" height="455" width="709"
            class="article-banner" alt="Mask2Former for Video Instance Segmentation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">Mask2Former for Video Instance Segmentation</a>
  </div>

  
  <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>SOTA video segmentation using Mask2Former.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2112.10764" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_videomask2former/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Mask2Former"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-spatial">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Bowen Cheng</span>, <span >
      Ishan Misra</span>, <span >
      Alexander G. Schwing</span>, <span >
      Alexander Kirillov</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2022
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_mask2former/featured_hu122a5880287eedad687316b306034f46_636930_017be73c8989c62f2324ab82603dca3c.webp" height="455" width="709"
            class="article-banner" alt="Masked-attention Mask Transformer for Universal Image Segmentation" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">Masked-attention Mask Transformer for Universal Image Segmentation</a>
  </div>

  
  <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Single architecture state-of-the-art in instance, semantic and panoptic segmentation.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2112.01527" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_mask2former/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Mask2Former"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-threed js-id-spatial">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICCV</em>, 2021 <strong>(Oral Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_3detr/featured_hu7f864dfc877057bf64d77be95f95f96d_503369_8d2cf20851d87e201b5366be63cc936c.webp" height="311" width="808"
            class="article-banner" alt="3DETR: An End-to-End Transformer Model for 3D Object Detection" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener">3DETR: An End-to-End Transformer Model for 3D Object Detection</a>
  </div>

  
  <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>First Transformer based detection architecture for 3D data.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2109.08141" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_3detr/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/3detr"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Kristen Grauman</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICCV</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_avt/featured_huf2660c77145987369cd52dc340a1c187_955803_808x455_fit_lanczos_1.gif" height="288" width="512"
            class="article-banner" alt="Anticipative Video Transformer" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener">Anticipative Video Transformer</a>
  </div>

  
  <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>An autoregressive video transformer architecture for action anticipation in videos.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2106.02036" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_avt/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/AVT"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-threed js-id-spatial">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Zhongzheng Ren</span>, <span >
      Ishan Misra</span>, <span >
      Alexander G. Schwing</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_wypr/featured_hufbafb9533b82cba7847e1f7b5e7080e5_238075_63100613de13106f19d3d9d4a311ddfd.webp" height="198" width="808"
            class="article-banner" alt="3D Spatial Recognition without Spatially Labeled 3D" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener">3D Spatial Recognition without Spatially Labeled 3D</a>
  </div>

  
  <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>WyPR can detect and segment objects in a 3D scene without needing any spatial labels at all!</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2105.06461" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_wypr/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://facebookresearch.github.io/WyPR/files/wypr_talk.pdf" target="_blank" rel="noopener">
  Slides
</a>








  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/WyPR"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-threed js-id-representation">
        
        











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Zaiwei Zhang</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="./publication/2021_depthcontrast/" >
      <div class="img-hover-zoom">
        <img src="./publication/2021_depthcontrast/featured_hu8b78c802ef23d72a1f175f8afba741c2_979869_bcbae38e92c7928693504553086e2fb1.webp" height="132" width="808"
            class="article-banner" alt="Self-Supervised Pretraining of 3D Features on any Point-Cloud" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="./publication/2021_depthcontrast/" >Self-Supervised Pretraining of 3D Features on any Point-Cloud</a>
  </div>

  
  <a href="./publication/2021_depthcontrast/"  class="summary-link">
    <div class="article-style">
      <p>SOTA 3D detection/segmentation results by learning contrastive representations on 3D data</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2101.02691" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_depthcontrast/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/DepthContrast"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-physics js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Eltayeb Ahmed</span>, <span >
      Anton Bakhtin</span>, <span >
      Laurens van der Maaten</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February, 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICML Workshops</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2021_dynamicsaware/featured_huec1d0a037ba36c31d05be3ac37ccd472_277358_17750f20d32f491cb8c46e037d7cb568.webp" height="158" width="808"
            class="article-banner" alt="Physical Reasoning Using Dynamics Aware Embeddings" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener">Physical Reasoning Using Dynamics Aware Embeddings</a>
  </div>

  
  <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Self-supervised representations for physical reasoning.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2102.10336" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_dynamicsaware/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="http://github.com/facebookresearch/DynamicsAware/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-physics js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Laura Gustafson</span>, <span >
      Aaron Adcock</span>, <span >
      Laurens van der Maaten</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICML Workshops</em>, 2021
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2020_fwdpred/featured_hu8d9b1a46deefea9f762c20cb30dc6055_78307_808x455_fit_lanczos_1.gif" height="400" width="400"
            class="article-banner" alt="Forward Prediction for Physical Reasoning" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener">Forward Prediction for Physical Reasoning</a>
  </div>

  
  <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Forward prediction for PHYRE benchmark.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2006.10734" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2020_fwdpred/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/phyre-fwd/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICLR</em>, 2020 <strong>(Oral Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2019_cater/featured_hu9755db045b8a61add6173c8ff4bede15_2134314_808x455_fit_lanczos_1.gif" height="240" width="320"
            class="article-banner" alt="CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener">CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>A dataset to evaluate temporal reasoning in video models.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1910.04744" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_cater/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://iclr.cc/virtual_2020/poster_HJgzt2VKPB.html" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="./CATER/assets/suppl/video.mp4" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/CATER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-generative js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Jessica Lee</span>, <span >
      Deva Ramanan</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICLR</em>, 2020
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2019_metapix/featured_hud9a104fcc45f35f9df298a521a0d0b46_3630474_808x455_fit_lanczos_1.gif" height="288" width="512"
            class="article-banner" alt="MetaPix: Few-Shot Video Retargeting" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener">MetaPix: Few-Shot Video Retargeting</a>
  </div>

  
  <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>A dataset to evaluate temporal reasoning in video models.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1910.04742" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_metapix/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://iclr.cc/virtual_2020/poster_SJx1URNKwH.html" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1wY5n8GNdWzoiOrpB67A2Y_TIZ9ANiP2G/view" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/imjal/MetaPix"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-video js-id-representation">
        
        











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Du Tran</span>, <span >
      Lorenzo Torresani</span>, <span >
      Deva Ramanan</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ICCV</em>, 2019
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="./publication/2019_distinit/" >
      <div class="img-hover-zoom">
        <img src="./publication/2019_distinit/featured_hu4e001f80c892f9e2c8c337bb4e4838eb_2596707_63e353ff22ca5a95ad520302100b1e1e.webp" height="414" width="808"
            class="article-banner" alt="DistInit: Learning Video Representations Without a Single Labeled Video" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="./publication/2019_distinit/" >DistInit: Learning Video Representations Without a Single Labeled Video</a>
  </div>

  
  <a href="./publication/2019_distinit/"  class="summary-link">
    <div class="article-style">
      <p>Distilling representations from image models to video models.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1901.09244" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_distinit/cite.bib">
  Cite
</a>
















  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-spatial js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      João Carreira</span>, <span >
      Carl Doersch</span>, <span >
      Andrew Zisserman</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2019 <strong>(Oral Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2018_actiontx/featured_hu1e036f46dd76096d1f2454972ba13709_3438152_808x455_fit_lanczos_1.gif" height="193" width="512"
            class="article-banner" alt="Video Action Transformer Network" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener">Video Action Transformer Network</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Among the first applications of Transformers to model videos. SOTA results: close 2nd at AVA Challenge, CVPR'18.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1812.02707" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2018_actiontx/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="./ActionTransformer/assets/video_present.mp4" target="_blank" rel="noopener">
  Video
</a>







  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-spatial js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Georgia Gkioxari</span>, <span >
      Lorenzo Torresani</span>, <span >
      Manohar Paluri</span>, <span >
      Du Tran</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December, 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2018
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2018_detectandtrack/featured_hu95f261a8f77cc4601de5664c77decdce_2713952_808x455_fit_lanczos_1.gif" height="180" width="320"
            class="article-banner" alt="Detect-and-Track: Efficient Pose Estimation in Videos" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener">Detect-and-Track: Efficient Pose Estimation in Videos</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Human keypoint tracking approach that ranked first in ICCV 2017 PoseTrack keypoint tracking challenge!</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1712.09184" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2018_detectandtrack/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/DetectAndTrack/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November, 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>NeurIPS</em>, 2017
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2017_attentionalpooling/featured_hub5744fc04efb48d32549ef4931a4139c_301991_c68182c26945bb3820d663321152b3c3.webp" height="351" width="808"
            class="article-banner" alt="Attentional Pooling for Action Recognition" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener">Attentional Pooling for Action Recognition</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Among the first applications of attention for contemporary video/action understanding.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1711.01467" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_attentionalpooling/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/AttentionalPoolingAction/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>, <span >
      Abhinav Gupta</span>, <span >
      Josef Sivic</span>, <span >
      Bryan Russell</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April, 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2017
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2017_actionvlad/featured_hu2dcdca03de97ac5220bc7e3318e9ee7d_702388_72a557176f1b9a325eaa4f95c0288db7.webp" height="455" width="762"
            class="article-banner" alt="ActionVLAD: Learning spatio-temporal aggregation for action classification" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener">ActionVLAD: Learning spatio-temporal aggregation for action classification</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Aggregating visual features for action recognition.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1704.02895" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_actionvlad/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=wVde6BPVUM0" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/ActionVLAD/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-video">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Xiaolong Wang</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Abhinav Gupta</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2016
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>CVPR</em>, 2017 <strong>(Spotlight Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2017_bingewatching/featured_huad3359525a476646203c34a9407edeff_1201126_8e097d82df6a798511688b70282a7ed9.webp" height="455" width="515"
            class="article-banner" alt="Binge Watching: Scaling Affordance Learning from Sitcoms" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener">Binge Watching: Scaling Affordance Learning from Sitcoms</a>
  </div>

  
  <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>Learning how humans interact with their environment by watching TV.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1804.03080" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_bingewatching/cite.bib">
  Cite
</a>
















  </div>
  

</div>

      </div>
    
      
        
          <div class="col-12 isotope-item js-id-selected js-id-threed js-id-generative">
        
        







  
  





  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      David F. Fouhey</span>, <span >
      Mikel Rodriguez</span>, <span >
      Abhinav Gupta</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2016
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <em>ECCV</em>, 2016 <strong>(Spotlight Presentation)</strong>
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    
    
    
    <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener">
      <div class="img-hover-zoom">
        <img src="./publication/2016_tl/featured_huf84016bb9da849beae6bbaeba5c4e68d_1194745_dc095ef71db31885a792d73f65ccba9e.webp" height="273" width="808"
            class="article-banner" alt="Learning a Predictable and Generative Vector Representation for Objects" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener">Learning a Predictable and Generative Vector Representation for Objects</a>
  </div>

  
  <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener" class="summary-link">
    <div class="article-style">
      <p>A single embedding space, good for both generating and understanding 3D models</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1603.08637" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2016_tl/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://videolectures.net/eccv2016_girdhar_vector_representation/" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/GenerativePredictableVoxels"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



  </div>
  

</div>

      </div>
    

  </div>
</div>


  
    </div>
  

  </div>
</section>

  



  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="./js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js"></script>




  
    <script src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":false}</script>











  
  


<script src="./en/js/wowchemy.min.b650e60aa2fd7385ff9cc14be4e3ea70.js"></script>



  <script src="./js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="./js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
