<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: May 7, 2025 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.6" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="../css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="../css/wowchemy.50b7bdfac32c4ce0cd2b02456081e75d.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="../css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="../css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Rohit Girdhar" />





  

<meta name="description" content="A highly-customizable Hugo academic resume theme powered by Hugo Blox Builder." />



<link rel="alternate" hreflang="en-us" href="https://rohitgirdhar.github.io/publication/" />
<link rel="canonical" href="https://rohitgirdhar.github.io/publication/" />



  <link rel="manifest" href="../manifest.webmanifest" />



<link rel="icon" type="image/png" href="../media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="../media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@GetResearchDev" />
  <meta property="twitter:creator" content="@GetResearchDev" />
<meta property="twitter:image" content="https://rohitgirdhar.github.io/media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_512x512_fill_lanczos_center_3.png" />



  

<meta property="og:type" content="website" />
<meta property="og:site_name" content="Rohit Girdhar" />
<meta property="og:url" content="https://rohitgirdhar.github.io/publication/" />
<meta property="og:title" content="Publications | Rohit Girdhar" />
<meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Hugo Blox Builder." /><meta property="og:image" content="https://rohitgirdhar.github.io/media/icon_huafb6545a7ac1b98e584f70276ee7d522_91451_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2025-01-30T00:00:00&#43;00:00" />
  










  
  
  

  
  
    <link rel="alternate" href="../publication/index.xml" type="application/rss+xml" title="Rohit Girdhar" />
  

  


  
  <title>Publications | Rohit Girdhar</title>

  
  
  
     
<script async defer src="https://buttons.github.io/buttons.js"></script>

  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="../js/wowchemy-init.min.3a6bdbdff5d8a89d6e651adb3deec035.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="../">Rohit Girdhar</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="../">Rohit Girdhar</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="../#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="../#projects"><span>Projects</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://twitter.com/_rohitgirdhar_" data-toggle="tooltip" data-placement="bottom" title="Follow me on Twitter" target="_blank" rel="noopener" aria-label="Follow me on Twitter">
                <i class="fab fa-twitter" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    
















  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>Publications</h1>

  

  
</div>



<div class="universal-wrapper">
  <div class="row">
    <div class="col-lg-12">

      

      
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      

      <div class="form-row mb-4">
        <div class="col-auto">
          <input type="search" class="filter-search form-control form-control-sm" placeholder="Search..." autocapitalize="off"
          autocomplete="off" autocorrect="off" role="textbox" spellcheck="false">
        </div>
        <div class="col-auto">
          <select class="pub-filters pubtype-select form-control form-control-sm" data-filter-group="pubtype">
            <option value="*">Type</option>
            
            <option value=".pubtype-paper-conference">
              Conference paper
            </option>
            
            <option value=".pubtype-paper-journal">
              Paper-Journal
            </option>
            
          </select>
        </div>
        <div class="col-auto">
          <select class="pub-filters form-control form-control-sm" data-filter-group="year">
            <option value="*">Date</option>
            
            
            
            <option value=".year-2025">
              2025
            </option>
            
            <option value=".year-2024">
              2024
            </option>
            
            <option value=".year-2023">
              2023
            </option>
            
            <option value=".year-2022">
              2022
            </option>
            
            <option value=".year-2021">
              2021
            </option>
            
            <option value=".year-2020">
              2020
            </option>
            
            <option value=".year-2019">
              2019
            </option>
            
            <option value=".year-2018">
              2018
            </option>
            
            <option value=".year-2017">
              2017
            </option>
            
            <option value=".year-2016">
              2016
            </option>
            
            
          </select>
        </div>
      </div>

      <div id="container-publications">
        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2025">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener">LLMs can see and hear without any training</a>
    </div>

    
    <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Pure text-only LLMs can use off-the-shelf multimodal embedding models to do various multimodal tasks!
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Kumar Ashutosh</span>, <span >
      Yossi Gandelsman</span>, <span >
      Xinlei Chen</span>, <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2501.18096" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2025_mils/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/MILS"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://github.com/facebookresearch/MILS" target="_blank" rel="noopener">
        <img src="../publication/2025_mils/featured_hu91feacf1bbb98f48740cb256b1527f7a_164182_065eda99d5ba8b33c92d586c4e8e4dac.webp" height="88" width="150"
            alt="LLMs can see and hear without any training" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2025">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener">Diffusion Autoencoders are Scalable Image Tokenizers</a>
    </div>

    
    <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Simplified image tokenization using diffusion
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yinbo Chen</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Xiaolong Wang</span>, <span >
      Sai Saketh Rambhatla</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2501.18593" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2025_dito/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/yinboc/dito"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://github.com/yinboc/dito" target="_blank" rel="noopener">
        <img src="../publication/2025_dito/featured_hucfdf306d236370f532f0af487a4c8716_124229_a362cda18fa5079c6a96f4efc67d28d7.webp" height="129" width="150"
            alt="Diffusion Autoencoders are Scalable Image Tokenizers" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2024">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener">MotiF: Making Text Count in Image Animation with Motion Focal Loss</a>
    </div>

    
    <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Using flow to improve motion in video generation
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Shijie Wang</span>, <span >
      Samaneh Azadi</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Saketh Rambhatla</span>, <span >
      Chen Sun</span>, <span >
      Xi Yin</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2412.16153" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_motif/cite.bib">
  Cite
</a>
















    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://wang-sj16.github.io/motif/" target="_blank" rel="noopener">
        <img src="../publication/2024_motif/featured_hub25141231e5184dde9bd7ca203a40cc3_3677564_150x0_resize_lanczos_1.gif" height="150" width="150"
            alt="MotiF: Making Text Count in Image Animation with Motion Focal Loss" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2024">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener">Movie Gen: A Cast of Media Foundation Models</a>
    </div>

    
    <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        State-of-the-Art Video (+Audio) Generation Model
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      MovieGen team (core-contributor)</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2410.13720" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_moviegen/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/playlist?list=PL86eLlsPNfyi27GSizYjinpYxp7gEl5K8" target="_blank" rel="noopener">
  Video
</a>







    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://ai.meta.com/research/movie-gen/" target="_blank" rel="noopener">
        <img src="../publication/2024_moviegen/featured_huf61b023c4e2bacd75707a055675aec31_18135496_150x0_resize_lanczos_1.gif" height="85" width="150"
            alt="Movie Gen: A Cast of Media Foundation Models" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2024">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener">The Llama 3 Herd of Models</a>
    </div>

    
    <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        State-of-the-Art open-source LLM with multimodal capabilities
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Llama3 team (co-lead the video recognition efforts)</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2407.21783" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_llama3/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/meta-llama/llama3"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener">
        <img src="../publication/2024_llama3/featured_hufc261de3a2ba4597fdb3fa01ac601ce8_5670404_150x0_resize_lanczos_1.gif" height="84" width="150"
            alt="The Llama 3 Herd of Models" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2024">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener">SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos</a>
    </div>

    
    <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Self-supervised embedding to learn how actions sound from narrated in-the-wild egocentric videos.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Changan Chen</span>, <span >
      Ashutosh Kumar</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      David Harwath</span>, <span >
      Kristen Grauman</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2404.05206" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_soundingactions/cite.bib">
  Cite
</a>
















    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://vision.cs.utexas.edu/projects/soundingactions/" target="_blank" rel="noopener">
        <img src="../publication/2024_soundingactions/featured_hu5df24b2c8c9426da5f6e4473bf397161_383944_4b5fe680abd48401382b72115f8ec856.webp" height="25" width="150"
            alt="SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2024">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener">InstanceDiffusion: Instance-level Control for Image Generation</a>
    </div>

    
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        SOTA instance-conditioned diffusion model for image generation.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xudong Wang</span>, <span >
      Trevor Darrell</span>, <span >
      Sai Saketh Rambhatla</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2402.03290" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2024_instancediffusion/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/frank-xwang/InstanceDiffusion"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/" target="_blank" rel="noopener">
        <img src="../publication/2024_instancediffusion/featured_hud09c74df147add9c2899425b89b23763_1717176_a09495abeaac45f72fbd59232fe947c0.webp" height="85" width="150"
            alt="InstanceDiffusion: Instance-level Control for Image Generation" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener">Generating Illustrated Instructions</a>
    </div>

    
    <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Introducing a new task of generating instructions for the task you want to solve with illustrations, and a LLM + Diffusion model based solution.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Sachit Menon</span>, <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2312.04552" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_illustratedinstructions/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/sachit-menon/generating-illustrated-instructions-reproduction"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/IllustratedInstructions/" target="_blank" rel="noopener">
        <img src="../publication/2023_illustratedinstructions/featured_huec897810e004554b234f684b1bd78268_967715_150x0_resize_lanczos_1.gif" height="167" width="150"
            alt="Generating Illustrated Instructions" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener">VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation</a>
    </div>

    
    <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        SOTA unsupervised video segmentation using CutLER.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xudong Wang</span>, <span >
      Ishan Misra</span>, <span >
      Ziyun Zeng</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Trevor Darrell</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2308.14710" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_videocutler/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/CutLER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://github.com/facebookresearch/CutLER" target="_blank" rel="noopener">
        <img src="../publication/2023_videocutler/featured_hu62e25aa308c4350caede4d3036165c7a_1324831_150x0_resize_lanczos_1.gif" height="29" width="150"
            alt="VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener">Motion-Conditioned Image Animation for Video Editing</a>
    </div>

    
    <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Image animation FTW again! SOTA video editing results by animating the first frame with motion conditioning.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Wilson Yan</span>, <span >
      Andrew Brown</span>, <span >
      Pieter Abbeel</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Samaneh Azadi</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2311.18827" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_moca/cite.bib">
  Cite
</a>
















    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/MoCA/" target="_blank" rel="noopener">
        <img src="../publication/2023_moca/featured_hu76aa32fa7e20fb2e5469631e3ce3167c_1637060_150x0_resize_lanczos_1.gif" height="75" width="150"
            alt="Motion-Conditioned Image Animation for Video Editing" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener">Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning</a>
    </div>

    
    <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        A simple and effective approach to high-quality video generation by learning to animate high quality images.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution, Equal First Author"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution, Equal First Author"></i>, <span >
      Andrew Brown</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Quentin Duval</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Samaneh Azadi</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Sai Saketh Rambhatla</span>, <span >
      Akbar Shah</span>, <span >
      Xi Yin</span>, <span >
      Devi Parikh</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2311.10709" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_emuvideo/cite.bib">
  Cite
</a>
















  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.meta.ai/" target="_blank" rel="noopener">
  Demo
</a>

    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://emu-video.metademolab.com/" target="_blank" rel="noopener">
        <img src="../publication/2023_emuvideo/featured_hu8a73aaf727f04e5575bcfb73288cf035_5778464_150x0_resize_lanczos_1.gif" height="150" width="150"
            alt="Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener">ImageBind: One Embedding Space To Bind Them All</a>
    </div>

    
    <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        One embedding space for 6 different modalities, enables zero-shot recognition on all modalities!
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alaaeldin El-Nouby</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Zhuang Liu</span>, <span >
      Mannat Singh</span>, <span >
      Kalyan Vasudev Alwala</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2305.05665" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_imagebind/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/W_zw4Lrdt1s" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/ImageBind"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://imagebind.metademolab.com/" target="_blank" rel="noopener">
        <img src="../publication/2023_imagebind/featured_huf79a6f7bcfb9d796f8906556960fe5f8_1189239_150x0_resize_lanczos_1.gif" height="123" width="150"
            alt="ImageBind: One Embedding Space To Bind Them All" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener">The effectiveness of MAE pre-pretraining for billion-scale pretraining</a>
    </div>

    
    <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Scaling up MAE pre-pretraining, followed by weakly supervised pretraining, leads to strong representations.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Quentin Duval</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Kalyan Vasudev Alwala</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Haoqi Fan</span>, <span >
      Vaibhav Aggarwal</span>, <span >
      Aaron Adcock</span>, <span >
      Armand Joulin</span>, <span >
      Piotr Dollár</span>, <span >
      Christoph Feichtenhofer</span>, <span >
      Ross Girshick</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2303.13496" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_maws/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/maws"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/maws/" target="_blank" rel="noopener">
        <img src="../publication/2023_maws/featured_hu9284505d0476bd57b25a1d4ef0ac7f95_215781_ef5094c396051218f4518b39a9c97e74.webp" height="124" width="150"
            alt="The effectiveness of MAE pre-pretraining for billion-scale pretraining" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener">CutLER: Cut and Learn for Unsupervised Object Detection and Instance Segmentation</a>
    </div>

    
    <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Discovering objects using DINO features, and learning an unsupervised detection + segmentation model
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xudong Wang</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Stella X. Yu</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2301.11320" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_cutler/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/CutLER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://people.eecs.berkeley.edu/~xdwang/projects/CutLER/" target="_blank" rel="noopener">
        <img src="../publication/2023_cutler/featured_hu71b3a50d5002fb490e347fa62c3e542a_1146224_e57741376184657395f949ba042b820f.webp" height="42" width="150"
            alt="CutLER: Cut and Learn for Unsupervised Object Detection and Instance Segmentation" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2023">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener">HierVL: Learning Hierarchical Video-Language Embeddings</a>
    </div>

    
    <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Video-language embeddings are a promising avenue for injecting semantics into visual representations, but existing methods capture only short-term associations between seconds-long video clips and their accompanying text. We propose HierVL, a novel hierarchical video-language embedding that simultaneously accounts for both long-term and short-term associations.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Kumar Ashutosh</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Lorenzo Torresani</span>, <span >
      Kristen Grauman</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2301.02311" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2023_hiervl/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=I5FIGHc_H5I" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/HierVL"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://vision.cs.utexas.edu/projects/hiervl/" target="_blank" rel="noopener">
        <img src="../publication/2023_hiervl/featured_hu313c0cd81089a238e84337ce628a6b31_182541_5cccda3294a7a81b911c6eef04d229d4.webp" height="122" width="150"
            alt="HierVL: Learning Hierarchical Video-Language Embeddings" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener">Learning Video Representations from Large Language Models</a>
    </div>

    
    <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Leveraging LLMs to auto-annotate videos for representation learning.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Yue Zhao</span>, <span >
      Ishan Misra</span>, <span >
      Philipp Krähenbühl</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2212.04501" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_lavila/cite.bib">
  Cite
</a>














  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://colab.research.google.com/drive/1gHWiEWywIotRivYQTR-8NQ6GJC7sJUe4" target="_blank" rel="noopener">
    Colab
</a>


  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/LaViLa"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/LaViLa/" target="_blank" rel="noopener">
        <img src="../publication/2022_lavila/featured_hub4c92471f059118ff9c3704afc0435e3_3559165_150x0_resize_lanczos_1.gif" height="113" width="150"
            alt="Learning Video Representations from Large Language Models" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener">Omnivore: A Single Model for Many Visual Modalities</a>
    </div>

    
    <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        A single model for images, video and single-view 3D.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Nikhila Ravi</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Laurens van der Maaten</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2201.08377" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_omnivore/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/omnivore"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/omnivore/" target="_blank" rel="noopener">
        <img src="../publication/2022_omnivore/featured_hu9cf3a85deea45bc635e5e78593f4f7a4_3052575_bbc2f1e3db6f8f72de21e2d882abc0d5.webp" height="56" width="150"
            alt="Omnivore: A Single Model for Many Visual Modalities" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022">
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="../publication/2022_omnimae/" >OmniMAE: Single Model Masked Pretraining on Images and Videos</a>
    </div>

    
    <a href="../publication/2022_omnimae/"  class="summary-link">
      <div class="article-style">
        Single self-supervised representation for images and videos.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alaaeldin El-Nouby</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Mannat Singh</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Kalyan Vasudev Alwala</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2206.08356" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_omnimae/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://youtu.be/qef4wWCytc4" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/omnivore"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="../publication/2022_omnimae/" >
        <img src="../publication/2022_omnimae/featured_hu1a7555a1b49baa03e14d96a4ba36e4c9_231964_1522492f28820d1ed2fa287606b01808.webp" height="46" width="150"
            alt="OmniMAE: Single Model Masked Pretraining on Images and Videos" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://ego4d-data.org/" target="_blank" rel="noopener">Ego4D: Around the World in 3,000 Hours of Egocentric Video</a>
    </div>

    
    <a href="https://ego4d-data.org/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        The largest egocentric video dataset.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Kristen Grauman</span>, <span >
      Andrew Westbury</span>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      et al</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2110.07058" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_ego4d/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=taC2ZKl9IsE" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Ego4D"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://ego4d-data.org/" target="_blank" rel="noopener">
        <img src="../publication/2022_ego4d/featured_hufaa5e2cae9d4f5980a8400d6f4dcc2af_4298806_150x0_resize_lanczos_1.gif" height="84" width="150"
            alt="Ego4D: Around the World in 3,000 Hours of Egocentric Video" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener">Detecting Twenty-thousand Classes using Image-level Supervision</a>
    </div>

    
    <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Leverages image classification data to build an object detector
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xingyi Zhou</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>, <span >
      Philipp Krähenbühl</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2201.02605" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2022_detic/cite.bib">
  Cite
</a>














  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://colab.research.google.com/drive/1QtTW9-ukX2HKZGvt0QvVGqjuqEykoZKI" target="_blank" rel="noopener">
    Colab
</a>


  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Detic"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://github.com/facebookresearch/Detic" target="_blank" rel="noopener">
        <img src="../publication/2022_detic/featured_hube32d62ba727a7e82c20c4a95ae4062f_140416_aed211231369fee4bff75914e52de4c7.webp" height="113" width="150"
            alt="Detecting Twenty-thousand Classes using Image-level Supervision" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-journal year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">Mask2Former for Video Instance Segmentation</a>
    </div>

    
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        SOTA video segmentation using Mask2Former.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Bowen Cheng</span>, <span >
      Anwesa Choudhuri</span>, <span >
      Ishan Misra</span>, <span >
      Alexander Kirillov</span>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Alexander G. Schwing</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2112.10764" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_videomask2former/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Mask2Former"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">
        <img src="../publication/2021_videomask2former/featured_hu122a5880287eedad687316b306034f46_636930_ffdb593319d0b4ff9a6ad524a1917cb4.webp" height="96" width="150"
            alt="Mask2Former for Video Instance Segmentation" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">Masked-attention Mask Transformer for Universal Image Segmentation</a>
    </div>

    
    <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Single architecture state-of-the-art in instance, semantic and panoptic segmentation.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Bowen Cheng</span>, <span >
      Ishan Misra</span>, <span >
      Alexander G. Schwing</span>, <span >
      Alexander Kirillov</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2112.01527" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_mask2former/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/Mask2Former"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://bowenc0221.github.io/mask2former/" target="_blank" rel="noopener">
        <img src="../publication/2021_mask2former/featured_hu122a5880287eedad687316b306034f46_636930_ffdb593319d0b4ff9a6ad524a1917cb4.webp" height="96" width="150"
            alt="Masked-attention Mask Transformer for Universal Image Segmentation" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener">3DETR: An End-to-End Transformer Model for 3D Object Detection</a>
    </div>

    
    <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        First Transformer based detection architecture for 3D data.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Ishan Misra</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2109.08141" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_3detr/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/3detr"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/3detr/" target="_blank" rel="noopener">
        <img src="../publication/2021_3detr/featured_hu7f864dfc877057bf64d77be95f95f96d_503369_c5ad66ab7bdc832d27822b3f16a9556c.webp" height="58" width="150"
            alt="3DETR: An End-to-End Transformer Model for 3D Object Detection" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener">Anticipative Video Transformer</a>
    </div>

    
    <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        An autoregressive video transformer architecture for action anticipation in videos.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Kristen Grauman</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2106.02036" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_avt/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/AVT"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/AVT/" target="_blank" rel="noopener">
        <img src="../publication/2021_avt/featured_huf2660c77145987369cd52dc340a1c187_955803_150x0_resize_lanczos_1.gif" height="84" width="150"
            alt="Anticipative Video Transformer" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="../publication/2021_depthcontrast/" >Self-Supervised Pretraining of 3D Features on any Point-Cloud</a>
    </div>

    
    <a href="../publication/2021_depthcontrast/"  class="summary-link">
      <div class="article-style">
        SOTA 3D detection/segmentation results by learning contrastive representations on 3D data
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Zaiwei Zhang</span>, <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Armand Joulin</span>, <span >
      Ishan Misra</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2101.02691" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_depthcontrast/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/DepthContrast"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="../publication/2021_depthcontrast/" >
        <img src="../publication/2021_depthcontrast/featured_hu8b78c802ef23d72a1f175f8afba741c2_979869_b5dd4323afe13b52ab9be9a2a0e163dd.webp" height="24" width="150"
            alt="Self-Supervised Pretraining of 3D Features on any Point-Cloud" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener">3D Spatial Recognition without Spatially Labeled 3D</a>
    </div>

    
    <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        WyPR can detect and segment objects in a 3D scene without needing any spatial labels at all!
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Zhongzheng Ren</span>, <span >
      Ishan Misra</span>, <span >
      Alexander G. Schwing</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2105.06461" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_wypr/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://facebookresearch.github.io/WyPR/files/wypr_talk.pdf" target="_blank" rel="noopener">
  Slides
</a>








  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/WyPR"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/WyPR/" target="_blank" rel="noopener">
        <img src="../publication/2021_wypr/featured_hufbafb9533b82cba7847e1f7b5e7080e5_238075_f07f26dfa4fa7f5da08c4af799ae48c7.webp" height="37" width="150"
            alt="3D Spatial Recognition without Spatially Labeled 3D" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener">Physical Reasoning Using Dynamics Aware Embeddings</a>
    </div>

    
    <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Self-supervised representations for physical reasoning.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Eltayeb Ahmed</span>, <span >
      Anton Bakhtin</span>, <span >
      Laurens van der Maaten</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2102.10336" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2021_dynamicsaware/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="http://github.com/facebookresearch/DynamicsAware/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/DynamicsAware/" target="_blank" rel="noopener">
        <img src="../publication/2021_dynamicsaware/featured_huec1d0a037ba36c31d05be3ac37ccd472_277358_e9d707e8f41bce22aafb26c003e9f811.webp" height="29" width="150"
            alt="Physical Reasoning Using Dynamics Aware Embeddings" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2020">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener">Forward Prediction for Physical Reasoning</a>
    </div>

    
    <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Forward prediction for PHYRE benchmark.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Laura Gustafson</span>, <span >
      Aaron Adcock</span>, <span >
      Laurens van der Maaten</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/2006.10734" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2020_fwdpred/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/phyre-fwd/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://facebookresearch.github.io/phyre-fwd/" target="_blank" rel="noopener">
        <img src="../publication/2020_fwdpred/featured_hu8d9b1a46deefea9f762c20cb30dc6055_78307_150x0_resize_lanczos_1.gif" height="150" width="150"
            alt="Forward Prediction for Physical Reasoning" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2019">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener">MetaPix: Few-Shot Video Retargeting</a>
    </div>

    
    <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        A dataset to evaluate temporal reasoning in video models.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Jessica Lee</span>, <span >
      Deva Ramanan</span>, <span class="author-highlighted">
      Rohit Girdhar</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1910.04742" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_metapix/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://iclr.cc/virtual_2020/poster_SJx1URNKwH.html" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/1wY5n8GNdWzoiOrpB67A2Y_TIZ9ANiP2G/view" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/imjal/MetaPix"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://imjal.github.io/MetaPix/" target="_blank" rel="noopener">
        <img src="../publication/2019_metapix/featured_hud9a104fcc45f35f9df298a521a0d0b46_3630474_150x0_resize_lanczos_1.gif" height="84" width="150"
            alt="MetaPix: Few-Shot Video Retargeting" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2019">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener">CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        A dataset to evaluate temporal reasoning in video models.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1910.04744" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_cater/cite.bib">
  Cite
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://iclr.cc/virtual_2020/poster_HJgzt2VKPB.html" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="../CATER/assets/suppl/video.mp4" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/CATER"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/CATER/" target="_blank" rel="noopener">
        <img src="../publication/2019_cater/featured_hu9755db045b8a61add6173c8ff4bede15_2134314_150x0_resize_lanczos_1.gif" height="113" width="150"
            alt="CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2019">
          







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="../publication/2019_distinit/" >DistInit: Learning Video Representations Without a Single Labeled Video</a>
    </div>

    
    <a href="../publication/2019_distinit/"  class="summary-link">
      <div class="article-style">
        Distilling representations from image models to video models.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Du Tran</span>, <span >
      Lorenzo Torresani</span>, <span >
      Deva Ramanan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1901.09244" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2019_distinit/cite.bib">
  Cite
</a>
















    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="../publication/2019_distinit/" >
        <img src="../publication/2019_distinit/featured_hu4e001f80c892f9e2c8c337bb4e4838eb_2596707_66d6f4b37513a4d9e6cdafff2652b892.webp" height="77" width="150"
            alt="DistInit: Learning Video Representations Without a Single Labeled Video" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2018">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener">Video Action Transformer Network</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Among the first applications of Transformers to model videos. SOTA results: close 2nd at AVA Challenge, CVPR'18.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      João Carreira</span>, <span >
      Carl Doersch</span>, <span >
      Andrew Zisserman</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1812.02707" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2018_actiontx/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="../ActionTransformer/assets/video_present.mp4" target="_blank" rel="noopener">
  Video
</a>







    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/ActionTransformer/" target="_blank" rel="noopener">
        <img src="../publication/2018_actiontx/featured_hu1e036f46dd76096d1f2454972ba13709_3438152_150x0_resize_lanczos_1.gif" height="57" width="150"
            alt="Video Action Transformer Network" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2017">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener">Detect-and-Track: Efficient Pose Estimation in Videos</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Human keypoint tracking approach that ranked first in ICCV 2017 PoseTrack keypoint tracking challenge!
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Georgia Gkioxari</span>, <span >
      Lorenzo Torresani</span>, <span >
      Manohar Paluri</span>, <span >
      Du Tran</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1712.09184" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2018_detectandtrack/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/facebookresearch/DetectAndTrack/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/DetectAndTrack/" target="_blank" rel="noopener">
        <img src="../publication/2018_detectandtrack/featured_hu95f261a8f77cc4601de5664c77decdce_2713952_150x0_resize_lanczos_1.gif" height="84" width="150"
            alt="Detect-and-Track: Efficient Pose Estimation in Videos" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2017">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener">Attentional Pooling for Action Recognition</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Among the first applications of attention for contemporary video/action understanding.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1711.01467" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_attentionalpooling/cite.bib">
  Cite
</a>















  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/AttentionalPoolingAction/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/AttentionalPoolingAction/" target="_blank" rel="noopener">
        <img src="../publication/2017_attentionalpooling/featured_hub5744fc04efb48d32549ef4931a4139c_301991_c0db97cf91ad4bb9da592e5dcf56c9e9.webp" height="65" width="150"
            alt="Attentional Pooling for Action Recognition" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2017">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener">ActionVLAD: Learning spatio-temporal aggregation for action classification</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Aggregating visual features for action recognition.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      Deva Ramanan</span>, <span >
      Abhinav Gupta</span>, <span >
      Josef Sivic</span>, <span >
      Bryan Russell</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1704.02895" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_actionvlad/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=wVde6BPVUM0" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/ActionVLAD/"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/ActionVLAD/" target="_blank" rel="noopener">
        <img src="../publication/2017_actionvlad/featured_hu2dcdca03de97ac5220bc7e3318e9ee7d_702388_1181e9727851bfe71172f69ebffcf792.webp" height="90" width="150"
            alt="ActionVLAD: Learning spatio-temporal aggregation for action classification" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2016">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener">Learning a Predictable and Generative Vector Representation for Objects</a>
    </div>

    
    <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        A single embedding space, good for both generating and understanding 3D models
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Rohit Girdhar</span>, <span >
      David F. Fouhey</span>, <span >
      Mikel Rodriguez</span>, <span >
      Abhinav Gupta</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1603.08637" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2016_tl/cite.bib">
  Cite
</a>










  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://videolectures.net/eccv2016_girdhar_vector_representation/" target="_blank" rel="noopener">
  Video
</a>






  
  
    
  

<span class="btn btn-outline-primary btn-page-header btn-sm" style="border: 0; margin: 0; padding: 0">
    <a class="github-button"
        href="https://github.com/rohitgirdhar/GenerativePredictableVoxels"
        data-icon="octicon-star"
        data-size="large"
        data-show-count="true"
        aria-label="Star ntkme/github-buttons on GitHub">Code</a>
</span>



    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://rohitgirdhar.github.io/GenerativePredictableVoxels/" target="_blank" rel="noopener">
        <img src="../publication/2016_tl/featured_huf84016bb9da849beae6bbaeba5c4e68d_1194745_f6a597b5ebc78f035ac16bc5a2988b93.webp" height="51" width="150"
            alt="Learning a Predictable and Generative Vector Representation for Objects" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2016">
          






  
  


  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener">Binge Watching: Scaling Affordance Learning from Sitcoms</a>
    </div>

    
    <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener" class="summary-link">
      <div class="article-style">
        Learning how humans interact with their environment by watching TV.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Xiaolong Wang</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span class="author-highlighted">
      Rohit Girdhar</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Abhinav Gupta</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/abs/1804.03080" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/2017_bingewatching/cite.bib">
  Cite
</a>
















    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      
      <a href="https://www.cs.cmu.edu/~xiaolonw/affordance.html" target="_blank" rel="noopener">
        <img src="../publication/2017_bingewatching/featured_huad3359525a476646203c34a9407edeff_1201126_d0833652148261ffdbfeba1701af8984.webp" height="133" width="150"
            alt="Binge Watching: Scaling Affordance Learning from Sitcoms" loading="lazy">
      </a>
    
  </div>
</div>

        </div>

        
      </div>

    </div>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="../js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js"></script>




  
    <script src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="../js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="../en/js/wowchemy.min.b650e60aa2fd7385ff9cc14be4e3ea70.js"></script>



  <script src="../js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="../js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
